{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Dispersion Entropy with top patterns\n\nDispersion Entropy is computed by first discretising the signal and then extracting all the\ndispersing patterns of given embedding dimension. The ditrubution of patterns determines the\ndispersion entropy of signal. If signal have a few patterns with high repetitions compare to others\nsignal is less random which entails the low entropy. On the other hand, a random signal with no\npatterns repetitions more than others leads to high entropy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport spkit as sp\nprint('spkit-version',sp.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "load sample EEG Signal\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X,fs,ch_names = sp.data.eeg_sample_14ch()\n\nXi = sp.filter_X(X[:,0],band=[1,20],btype='bandpass',verbose=0)\nprint('EEG Sample : Shape',Xi.shape)\nt = np.arange(Xi.shape[0])/fs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dispersion Entropy\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Dispersion Entropy with embeding dimention=4')\nprint('-'*10)\n\nde,prob,patterns_dict,_,_= sp.dispersion_entropy(Xi,classes=10, scale=1, emb_dim=4, delay=1,return_all=True)\nprint('Disperssion Entropy: ',de)\n\n\n\nPP = np.array([list(k)+[patterns_dict[k]] for k in patterns_dict])\nidx = np.argsort(PP[:,-1])[::-1]\nprint('Top 10 Patterns')\nprint(PP[idx[:10],:-1])\n\nPtop = np.array(list(PP[idx,:-1]))\nidx2 = np.where(np.sum(np.abs(Ptop-Ptop.mean(1)[:,None]),1)>0)[0]\n\nfig = plt.figure(figsize=(12,6))\nplt.subplot(3,1,1)\nplt.plot(t,Xi)\nplt.xlim([0,t[-1]])\nplt.xlabel('time (s)')\nplt.grid()\nplt.title(f'Disperssion Entropy: {de}')\n#plt.ylabel('Signal')\nfor i in range(10):\n    plt.subplot(3,5,i+6)\n    plt.plot(Ptop[idx2[i]].astype(int))\n    plt.grid()\n    plt.yticks(np.unique(Ptop[idx2[i]]))\n    plt.title(f'#{i+1}')\n\nfig.suptitle('Dispersion Entropy and Top 10 non-flat Patterns')\nplt.tight_layout()\nplt.show()\n\n\nfig = plt.figure(figsize=(12,5))\nplt.subplot(121)\nplt.stem(np.arange(len(prob)),prob)\nplt.xlabel('pattern #')\nplt.ylabel('probability')\nplt.title(f'Disperssion Entropy: {de}')\nplt.subplot(122)\nplt.plot(Ptop[idx2[:10]].T,'--o')\nplt.xticks([0,1,2,3])\nplt.grid()\nplt.title('Top 10 non-flat Patterns')\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Decision Trees with shrinking capability - Regression example\n\nDecision Trees with shrinking capability from SpKit (Regression example)\n\nIn this notebook, we show the capability of decision tree from ***spkit*** to analysie the training and testing performace at each depth of a trained tree. After which, a trained tree can be shrink to any smaller depth, ***without retraining it***. So, by using Decision Tree from ***spkit***, you could choose a very high number for a **max_depth** (or just choose -1, for infinity) and analysis the parformance (accuracy, mse, loss) of training and testing (practically, a validation set) sets at each depth level. Once you decide which is the right depth, you could shrink your trained tree to that layer, without explicit training it again to with new depth parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport spkit\nprint('spkit version :', spkit.__version__)\n\n# just to ensure the reproducible results\nnp.random.seed(100) \n\n# Regression - Diabetes Dataset - score\n\nfrom spkit.ml import RegressionTree\n\n\nfrom sklearn.datasets import load_diabetes\ndata = load_diabetes()\nX = data.data\ny = data.target\n\nfeature_names = data.feature_names\nprint(X.shape, y.shape)\nXt,Xs,yt,ys = train_test_split(X,y,test_size =0.3)\nprint(Xt.shape, Xs.shape,yt.shape, ys.shape)\n\n\n# ### Train with max_depth=15, MSE, MAE\n\n\nmodel = RegressionTree(max_depth=15)\nmodel.fit(Xt,yt,feature_names=feature_names)\nytp = model.predict(Xt)\nysp = model.predict(Xs)\nprint('Depth of trained Tree ', model.getTreeDepth())\nprint('MSE')\nprint('- Training : ',np.mean((ytp-yt)**2))\nprint('- Testing  : ',np.mean((ysp-ys)**2))\nprint('MAE')\nprint('- Training : ',np.mean(np.abs(ytp-yt)))\nprint('- Testing  : ',np.mean(np.abs(ysp-ys)))\n\n\n#  Plot trained Tree\n\nplt.figure(figsize=(15,12))\nmodel.plotTree()\n\n\n#  Analysing the Learning Curve and Tree with MAE\n\nLcurve = model.getLcurve(Xt=Xt,yt=yt,Xs=Xs,ys=ys,measure='mae')\nprint(Lcurve)\n\n\nmodel.plotLcurve()\nplt.xlim([1,model.getTreeDepth()])\nplt.xticks(np.arange(1,model.getTreeDepth()+1))\nplt.show()\n\n\nplt.figure(figsize=(10,8))\nmodel.plotTree(show=False,Measures=True,showNodevalues=True,showThreshold=False)\n\n\n# Shrining a trained Tree to depth=2\n\nmodel.updateTree(shrink=True,max_depth=2)\n\n\nytp = model.predict(Xt)\nysp = model.predict(Xs)\nprint('Depth of trained Tree ', model.getTreeDepth())\nprint('MSE')\nprint('- Training : ',np.mean((ytp-yt)**2))\nprint('- Testing  : ',np.mean((ysp-ys)**2))\nprint('MAE')\nprint('- Training : ',np.mean(np.abs(ytp-yt)))\nprint('- Testing  : ',np.mean(np.abs(ysp-ys)))\n\n\nplt.figure(figsize=(10,5))\nmodel.plotTree(show=False,Measures=True,showNodevalues=True,showThreshold=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
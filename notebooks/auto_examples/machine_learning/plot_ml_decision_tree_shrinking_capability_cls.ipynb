{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Decision Trees with shrinking capability - Classification example\n\n\nDecision Trees with shrinking capability from SpKit (Classification example)\n\nIn this notebook, we show the capability of decision tree from ***spkit*** to analysie the training and testing performace at each depth of a trained tree. After which, a trained tree can be shrink to any smaller depth, ***without retraining it***. So, by using Decision Tree from ***spkit***, you could choose a very high number for a **max_depth** (or just choose -1, for infinity) and analysis the parformance (accuracy, mse, loss) of training and testing (practically, a validation set) sets at each depth level. Once you decide which is the right depth, you could shrink your trained tree to that layer, without explicit training it again to with new depth parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport spkit\nprint('spkit version :', spkit.__version__)\n\n# just to ensure the reproducible results\nnp.random.seed(100) \n\n# Classification  - Diabetes Dataset -  binary class\n\nfrom spkit.ml import ClassificationTree\n\n# Diabetes Dataset\nfrom sklearn.datasets import load_diabetes\ndata = load_diabetes()\nX = data.data\ny = 1*(data.target>np.mean(data.target))\n\nfeature_names = data.feature_names\nprint(X.shape, y.shape)\nXt,Xs,yt,ys = train_test_split(X,y,test_size =0.3)\nprint(Xt.shape, Xs.shape,yt.shape, ys.shape)\n\n\n# Train with max_depth =15, Accuracy, Logloss\n\nmodel = ClassificationTree(max_depth=15)\nmodel.fit(Xt,yt,feature_names=feature_names)\nytp = model.predict(Xt)\nysp = model.predict(Xs)\n\nytpr = model.predict_proba(Xt)[:,1]\nyspr = model.predict_proba(Xs)[:,1]\n\nprint('Depth of trained Tree ', model.getTreeDepth())\nprint('Accuracy')\nprint('- Training : ',np.mean(ytp==yt))\nprint('- Testing  : ',np.mean(ysp==ys))\nprint('Logloss')\nTrloss = -np.mean(yt*np.log(ytpr+1e-10)+(1-yt)*np.log(1-ytpr+1e-10))\nTsloss = -np.mean(ys*np.log(yspr+1e-10)+(1-ys)*np.log(1-yspr+1e-10))\nprint('- Training : ',Trloss)\nprint('- Testing  : ',Tsloss)\n\n\n# Plot Trained Tree\n\nplt.figure(figsize=(15,12))\nmodel.plotTree()\n\n\n# Analysing the Learning Curve with test data (validation set)\n\nLcurve = model.getLcurve(Xt=Xt,yt=yt,Xs=Xs,ys=ys,measure='acc')\nprint(Lcurve)\n\nmodel.plotLcurve()\nplt.xlim([1,model.getTreeDepth()])\nplt.xticks(np.arange(1,model.getTreeDepth()+1))\nplt.show()\n\n\n# Learning curve with tree\n\nplt.figure(figsize=(10,8))\nmodel.plotTree(show=False,Measures=True,showNodevalues=True,showThreshold=False)\n\n\n# Shrinking the trained tree to depth=7\n\nmodel.updateTree(shrink=True,max_depth=7)\n\n\nytp = model.predict(Xt)\nysp = model.predict(Xs)\n\nytpr = model.predict_proba(Xt)[:,1]\nyspr = model.predict_proba(Xs)[:,1]\n\nprint('Depth of trained Tree ', model.getTreeDepth())\nprint('Accuracy')\nprint('- Training : ',np.mean(ytp==yt))\nprint('- Testing  : ',np.mean(ysp==ys))\nprint('Logloss')\nTrloss = -np.mean(yt*np.log(ytpr+1e-10)+(1-yt)*np.log(1-ytpr+1e-10))\nTsloss = -np.mean(ys*np.log(yspr+1e-10)+(1-ys)*np.log(1-yspr+1e-10))\nprint('- Training : ',Trloss)\nprint('- Testing  : ',Tsloss)\n\n\n# # Plotting final tree\n\nplt.figure(figsize=(10,6))\nmodel.plotTree(show=False,Measures=True,showNodevalues=True,showThreshold=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
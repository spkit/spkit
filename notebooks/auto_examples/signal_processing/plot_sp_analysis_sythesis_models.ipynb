{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Analysis and Synthesis Models\n\nAnalysis and Synthesis Models\n\nIn this script, we demonstrate following four models:\n\n* 1 DFT Model\n* 2 STFT Model\n* 3 Fractional Fourier Transform: FRFT\n* 4 Sinasodual Model: Audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport spkit as sp\nprint('spkit version :', sp.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 DFT Model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X,fs, ch_names = sp.data.eeg_sample_14ch()\n\nx = X[:,1]\nt = np.arange(len(x))/fs\nprint(x.shape)\n\n\n# Analysis\n\nmX, pX, N = sp.dft_analysis(x, window='boxcar')\nprint(mX.shape,pX.shape, N)\n\n\n# Synthesis\n\ny = sp.dft_synthesis(mX, pX, M=N, window='boxcar')\nprint(y.shape)\n\n\n# plots\n\nplt.figure(figsize=(13,8))\nplt.subplot(311)\nplt.plot(t,x)\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.xlabel('time (s)')\nplt.title('Original signal')\nplt.ylabel('amplitude (\u03bcV)')\n\nplt.subplot(323)\nfr = (fs/2)*np.arange(len(mX))/(len(mX)-1)\nplt.plot(fr,mX)\nplt.xlim([fr[0],fr[-1]])\nplt.grid()\nplt.ylabel('|X| (dB)')\nplt.title('Magnitude spectrum')\nplt.subplot(324)\nplt.plot(fr,pX)\nplt.xlim([fr[0],fr[-1]])\nplt.grid()\nplt.ylabel('<|X|')\nplt.title('Phase spectrum')\n\nplt.subplot(313)\nplt.plot(t,y)\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.title('Reconstructed signal')\nplt.xlabel('time (s)')\nplt.ylabel('amplitude (\u03bcV)')\nplt.tight_layout()\nplt.show()\n\n\nmX, pX, N = sp.dft_analysis(x, window='boxcar',plot=2, fs=fs)\n\n\n# windowing effect\n\nmX, pX, N = sp.dft_analysis(x, window='hamm',plot=2, fs=fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 STFT Model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X,fs, ch_names = sp.data.eeg_sample_14ch()\nx = X[:,1]\nt = np.arange(len(x))/fs\nprint(x.shape)\n\n\n# Analysis: STFT\n\n\nmXt,pXt = sp.stft_analysis(x, winlen=128, overlap=32,window='blackmanharris',nfft=None)\nprint(mXt.shape, pXt.shape)\n\n\n#  Synthesis: Inverse STFT\n\ny = sp.stft_synthesis(mXt, pXt, winlen=128, overlap=32)\nprint(y.shape)\n\n\n#  plots\n\n\nplt.figure(figsize=(13,8))\nplt.subplot(311)\nplt.plot(t,x)\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.title('Original signal')\nplt.ylabel('amplitude (\u03bcV)')\n\nplt.subplot(312)\nplt.imshow(mXt.T,aspect='auto',origin='lower',cmap='jet',extent=[t[0],t[-1],0,fs/2])\nplt.title('STFT: Spectrogram')\nplt.ylabel('frequency (Hz)')\n\nplt.subplot(313)\nplt.plot(t,y[:len(t)])\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.title('Reconstructed signal')\nplt.xlabel('time (s)')\nplt.ylabel('amplitude (\u03bcV)')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Fractional Fourier Transform: FRFT\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X,fs, ch_names = sp.data.eeg_sample_14ch()\n\nx = X[:,1]\nt = np.arange(len(x))/fs\nprint(x.shape)\n\n\n#  Analysis\n\nXa = sp.frft(x.copy(),alpha=0.2)\nprint(Xa.shape)\n\n\n# Synthesis\n\ny = sp.ifrft(Xa.copy(),alpha=0.2)\nyi = sp.frft(Xa.copy(),alpha=-0.2)\ny.shape\n\n# plots\n\nplt.figure(figsize=(13,6))\nplt.subplot(311)\nplt.plot(t,x)\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.title('x(t)')\n#plt.xlabel('time (s)')\nplt.ylabel('amplitude (\u03bcV)')\n\nplt.subplot(312)\nplt.plot(t,Xa.real,label='real')\nplt.plot(t,Xa.imag,label='imag')\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.title(r'FRFT(x(t)), $\\alpha=0.2$')\n#plt.xlabel('time (s)')\nplt.ylabel('amplitude (\u03bcV)')\nplt.legend()\n\n\nplt.subplot(313)\nplt.plot(t,y.real)\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.title('Reconstructed signal: x(t)')\n#plt.xlabel('time (s)')\nplt.ylabel('amplitude (\u03bcV)')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 Sinasodual Model: Audio\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Reading audio file from url\n\nimport requests\nfrom scipy.io import wavfile\n\n#uncomment in jupyter-notebook\n#import IPython\n\npath1 = 'https://github.com/Nikeshbajaj/web-data/blob/main/sounds/violin-B3.wav?raw=true'\npath2 = 'https://github.com/Nikeshbajaj/web-data/blob/main/sounds/singing-female.wav?raw=true'\nprint(path2)\n\n\n\nreq = requests.get(path2)\nwith open('myfile.wav', 'wb') as f:\n        f.write(req.content)\n        \nfs, x = wavfile.read('myfile.wav')\nt = np.arange(len(x))/fs\nx=x.astype(float)\nprint(x.shape, fs)\n\n#  Analysis: Decompising into N-sinasodal tracks\n\n\nN=20\n\nfXst, mXst, pXst = sp.sineModel_analysis(x,fs,winlen=3001,overlap=750,\n                            window='blackmanharris', nfft=None, thr=-10, \n                            maxn_sines=N,minDur=0.01, freq_devOffset=10,freq_devSlope=0.1)\n\nprint(fXst.shape, mXst.shape, pXst.shape)\n\n\n# Synthesis of audio from N-sinasodal tracks\n\n\nXr = sp.sineModel_synthesis(fXst, mXst, pXst,fs,overlap=750,crop_end=False)\nprint(Xr.shape)\n\n#  plots\n\n\nplt.figure(figsize=(13,15))\nplt.subplot(511)\nplt.plot(t,x)\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.title('Original Auido: x(t)')\n#plt.xlabel('time (s)')\nplt.ylabel('amplitude (\u03bcV)')\n\nmXt,pXt = sp.stft_analysis(x, winlen=441, overlap=220,window='blackmanharris',nfft=None)\n\nplt.subplot(512)\nplt.imshow(mXt.T,aspect='auto',origin='lower',cmap='jet',extent=[t[0],t[-1],0,fs/2])\nplt.title('Spectrogram of x(t)')\n#plt.xlabel('time (s)')\nplt.ylabel('frequency (Hz)')\n\n\nfXt1 = (fXst.copy())*(mXst>0)\nfXt1[fXt1==0]=np.nan\n\n\nplt.subplot(513)\ntx = t[-1]*np.arange(fXt1.shape[0])/fXt1.shape[0]\n\nplt.plot(tx,fXt1,'-k',alpha=0.5)\n#plt.ylim([0,fs/2])\nplt.xlim([0,tx[-1]])\n\nplt.title(f'Sinasodals Tracks: n={N}')\nplt.xlabel('time (s)')\nplt.ylabel('frequency (Hz)')\nplt.grid(alpha=0.3)\n\n\n\nplt.subplot(514)\nplt.plot(t,Xr[:len(t)])\nplt.xlim([t[0],t[-1]])\nplt.grid()\nplt.title(f'Reconstructed Audio from {N} Sinasodals: $x_r(t)$')\n#plt.xlabel('time (s)')\nplt.ylabel('amplitude')\n\n\nmXrt,pXrt = sp.stft_analysis(Xr, winlen=441, overlap=220,window='blackmanharris',nfft=None)\n\nplt.subplot(515)\nplt.imshow(mXrt.T,aspect='auto',origin='lower',cmap='jet',extent=[t[0],t[-1],0,fs/2])\nplt.title(r'Spectrogram of $x_r(t)$')\n#plt.xlabel('time (s)')\nplt.ylabel('frequency (Hz)')\nplt.tight_layout()\nplt.show()\n\n#uncomment in jupyter-notebook\n#print('Original Audio: $x(t)$')\n#display(IPython.display.Audio(x,rate=fs))\n\n#print(f'Reconstructed Audio: $x_r(t)$')\n#display(IPython.display.Audio(Xr,rate=fs))\n\n\n\nwavfile.write('singing_female_recons.wav', rate=fs, data=Xr.astype('int16'))\nwavfile.write('singing_female_residual.wav', rate=fs, data=(x-Xr[:len(x)]).astype('int16'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### saved audio files\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "embed_audio('singing_female_recons', attribute = c(\"controls\", \"loop\"))\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# embed_audio('singing_female_recons', attribute = c(\"controls\", \"loop\"))\n\n\n# embed_audio('https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing-female.wav', attribute = c(\"controls\", \"loop\"))\n\n# ![]('https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing-female.wav')\n\n# ![]('https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing-female.wav')\n\n# Original Audio\n# \n# <audio controls=\"controls\">\n#       <source src=\"https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing-female.wav\" type=\"audio/wav\"> \n# </audio>\n# \n# https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing-female.wav\n# \n# \n# Reconstructed Audio\n# \n# <audio controls=\"controls\">\n#       <source src=\"https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing_female_recons.wav\" type=\"audio/wav\">\n# </audio>\n# \n# https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing_female_recons.wav\n# \n# \n# Residual Audio   \n# <audio controls=\"controls\">\n#       <source src=\"https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing_female_residual.wav\" type=\"audio/wav\">\n# </audio>\n# \n# https://raw.githubusercontent.com/Nikeshbajaj/spkit/master/spkit/data/singing_female_residual.wav"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}